{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0815b746931c540dd900bc689bff56968bb61769b1159081e25b8d44643e03281",
   "display_name": "Python 3.9.5 64-bit ('Python39')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "課題３"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "source": [
    "レンダリングに必要な関数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_Lambert(I, x, l_point, n, k_d):\n",
    "    xl = l_point - x\n",
    "    r = np.linalg.norm(xl)\n",
    "    l = xl/r\n",
    "\n",
    "    return k_d*(I/r**2)*max(0, np.dot(l.T, n)[0][0])\n",
    "\n",
    "def rel_environment(I_a, k_a):\n",
    "    return k_a*I_a\n",
    "\n",
    "def raymarching(ray, forcus, sdf):\n",
    "    beta = 0.05\n",
    "    vec_ray = beta*(ray/np.linalg.norm(ray))\n",
    "    x = forcus + vec_ray\n",
    "    dist, vec_n= sdf(x)\n",
    "\n",
    "    flag = True\n",
    "    step = 0\n",
    "    while -1e-1 > dist or dist > 1e-1:\n",
    "        \n",
    "        pre_dist = dist\n",
    "        if dist > 0:\n",
    "            x = x + vec_ray\n",
    "            dist, vec_n = sdf(x)\n",
    "        else:\n",
    "            x = x - 0.01*vec_ray\n",
    "            dist, vec_n = sdf(x)\n",
    "            flag = False\n",
    "\n",
    "\n",
    "        if flag and pre_dist < dist: #no material is same return\n",
    "            return forcus, np.zeros((3,1))\n",
    "\n",
    "        if step == 20:\n",
    "            return forcus, np.zeros((3,1))\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    return x, vec_n"
   ]
  },
  {
   "source": [
    "多層ニューラルネット定義"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_fig = 'output/fig'\n",
    "OUTPUT_csv = 'output/csv'\n",
    "os.makedirs(OUTPUT_csv, exist_ok=True)\n",
    "os.makedirs(OUTPUT_fig, exist_ok=True)\n",
    "\n",
    "#train data set\n",
    "logo_df = pd.read_csv('data/logo.csv')\n",
    "x_train = logo_df.to_numpy()\n",
    "t_train = np.zeros((x_train.shape[0], 1))\n",
    "\n",
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_train, t_train):\n",
    "        self.x_train = x_train.astype('float32')\n",
    "        self.t_train = t_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x_train[idx], dtype=torch.float), torch.tensor(t_train[idx], dtype=torch.long)\n",
    "\n",
    "trainval_data = dataset(x_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "batch_size = 32\n",
    "val_size = 1000\n",
    "train_size = len(trainval_data) - val_size\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "dataloader_valid = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "source": [
    "deepSDFクラス"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初期値の関数\n",
    "def init_weights_xav(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "def init_weights_he(m):  # He\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "#ネットワーク\n",
    "class deepSDF(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, 6),\n",
    "            nn.BatchNorm1d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 12),\n",
    "            nn.BatchNorm1d(12),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(12, 24),\n",
    "            nn.BatchNorm1d(24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 12),\n",
    "            nn.BatchNorm1d(12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 6),\n",
    "            nn.BatchNorm1d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 3),\n",
    "            nn.BatchNorm1d(3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(3, out_dim),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "            nn.Tanh()\n",
    "        ).apply(init_weights_he)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "    def sdf(self, x):\n",
    "        x = x.reshape((3,))\n",
    "        x = torch.tensor(x, dtype=torch.float, requires_grad=True).unsqueeze(0)\n",
    "        x.retain_grad()\n",
    "        y = self.layer(x)\n",
    "        y.backward()\n",
    "\n",
    "        vec_n = 100*x.grad.to('cpu').detach().numpy().copy().reshape((3,1))\n",
    "        return y.item(), vec_n/np.linalg.norm(vec_n)\n",
    "\n",
    "\n",
    "#誤差関数\n",
    "def loss_function(y, t, delta=0.1):\n",
    "    y_cl = torch.clamp(y, min=-delta, max=delta)\n",
    "    t_cl = torch.clamp(t, min=-delta, max=delta)\n",
    "\n",
    "    return torch.abs(y_cl - t_cl).sum()\n",
    "\n",
    "\n",
    "lr = 5e-3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = deepSDF(3,1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "source": [
    "学習"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "\n",
    "    model.train()\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    for x, t in dataloader_train:\n",
    "        n_train += t.size()[0]\n",
    "        model.zero_grad()\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        y = model(x)\n",
    "        loss = loss_function(y, t)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc_train += (torch.abs(y) < torch.tensor(0.05)).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "\n",
    "    model.eval()\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    for x, t in dataloader_valid:\n",
    "        n_val += t.size()[0]\n",
    "        model.zero_grad()\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        y = model(x)\n",
    "        loss = loss_function(y, t)\n",
    "\n",
    "        acc_val += (torch.abs(y) < torch.tensor(0.05)).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n",
    "        epoch,\n",
    "        np.mean(losses_train),\n",
    "        acc_train/n_train,\n",
    "        np.mean(losses_valid),\n",
    "        acc_val/n_val\n",
    "    ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotation transration\n",
    "theta = 45\n",
    "cos = np.cos(np.radians(theta))\n",
    "sin = np.sin(np.radians(theta))\n",
    "R = [[1, 0, 0],\n",
    "     [0, cos, -sin],\n",
    "     [0, sin, cos]]\n",
    "R = np.array(R)\n",
    "T = [1, -2.5, 2.5]\n",
    "T = np.array(T).reshape((3,1))\n",
    "A = np.append(R, T, axis=1)\n",
    "#camera\n",
    "camera = [0,0,0,1]\n",
    "camera = np.array(camera).reshape((4,1))\n",
    "camera = np.dot(A, camera)\n",
    "#screen\n",
    "screen = np.zeros((500,500))\n",
    "#camera matrix\n",
    "K = np.eye(3)\n",
    "f_x = 20\n",
    "f_y = 20\n",
    "K[0,0] = f_x\n",
    "K[1,1] = f_y\n",
    "K[0,2] = 250\n",
    "K[1,2] = 250\n",
    "#parameter\n",
    "I = 5\n",
    "k_d = 10\n",
    "I_a = 1\n",
    "k_a = 1"
   ]
  },
  {
   "source": [
    "モデルをレンダリング"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = int(screen.shape[0]/2)\n",
    "hight = int(screen.shape[1]/2)\n",
    "\n",
    "for i in tqdm(range(-width, width)):\n",
    "    i = i/f_x\n",
    "    for j in range(-hight, hight):\n",
    "        j = j/f_y\n",
    "        forcus = [i, j, 1, 1]\n",
    "        forcus = np.array(forcus).reshape((4,1))\n",
    "        forcus_camera = forcus[:3,:]\n",
    "        forcus = np.dot(A, forcus)\n",
    "        ray = forcus - camera\n",
    "        x, vec_n = raymarching(ray, forcus, model.sdf)\n",
    "\n",
    "        if np.array_equal(forcus, x):\n",
    "            vec_sc = np.dot(K, forcus_camera)\n",
    "            screen[int(vec_sc[0][0]), int(vec_sc[1][0])] = 0\n",
    "        else:\n",
    "            vec_sc = np.dot(K, forcus_camera)\n",
    "            screen[int(vec_sc[0][0]), int(vec_sc[1][0])] = rel_Lambert(I, x, camera, vec_n, k_d) + rel_environment(I_a,k_a)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(screen.T, 'gray')\n",
    "plt.imsave(OUTPUT_fig+'/ex3.jpg', screen.T)\n",
    "plt.show()"
   ]
  }
 ]
}