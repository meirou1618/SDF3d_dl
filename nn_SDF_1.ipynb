{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0514466fe9bdbb4465d0f72d486e68777ccb9801e0d08f857a8c5a4c505647bc4",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_fig = 'output/fig'\n",
    "OUTPUT_csv = 'output/csv'\n",
    "os.makedirs(OUTPUT_csv, exist_ok=True)\n",
    "os.makedirs(OUTPUT_fig, exist_ok=True)\n",
    "\n",
    "#train data set\n",
    "logo_df = pd.read_csv('data/logo.csv')\n",
    "x_train = logo_df.to_numpy()\n",
    "t_train = np.zeros((x_train.shape[0], 1))\n",
    "\n",
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_train, t_train):\n",
    "        self.x_train = x_train.astype('float32')\n",
    "        self.t_train = t_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x_train[idx], dtype=torch.float), torch.tensor(t_train[idx], dtype=torch.long)\n",
    "\n",
    "trainval_data = dataset(x_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "val_size = 1000\n",
    "train_size = len(trainval_data) - val_size\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(trainval_data, [train_size, val_size])\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "dataloader_valid = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_xav(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "def init_weights_he(m):  # He\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "class deepSDF(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim):\n",
    "        super().__init__()\n",
    "        # self.layer = nn.Sequential(\n",
    "        #     nn.Linear(in_dim, out_dim),\n",
    "        #     nn.BatchNorm1d(out_dim),\n",
    "        #     nn.Tanh()\n",
    "        # ).apply(init_weights_xav)\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.BatchNorm1d(hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, 4),\n",
    "            nn.BatchNorm1d(hid_dim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(4, 3),\n",
    "            nn.BatchNorm1d(3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 2),\n",
    "            nn.BatchNorm1d(2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(2, out_dim),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "            nn.Tanh()\n",
    "        ).apply(init_weights_he)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "    def sdf(self, x):\n",
    "        x = x.reshape((3,))\n",
    "        x = torch.tensor(x, dtype=torch.float, requires_grad=True).unsqueeze(0)\n",
    "        x.retain_grad()\n",
    "        y = self.layer(x)\n",
    "        y.backward()\n",
    "\n",
    "        vec_n = 50*x.grad.to('cpu').detach().numpy().copy().reshape((3,1))\n",
    "        #print(vec_n)\n",
    "        return y.item(), vec_n/np.linalg.norm(vec_n)\n",
    "        # y = self.layer(x)\n",
    "        # w = self.layer[0].weight.to('cpu').detach().numpy().copy().reshape((3,1))\n",
    "        # y = y.item()\n",
    "        # return y, (1 - y**2)*w\n",
    "\n",
    "\n",
    "def loss_function(y, t, delta=0.1):\n",
    "    y_cl = torch.clamp(y, min=-delta, max=delta)\n",
    "    t_cl = torch.clamp(t, min=-delta, max=delta)\n",
    "\n",
    "    return torch.abs(y_cl - t_cl).sum()\n",
    "\n",
    "\n",
    "lr = 5e-3\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = deepSDF(3,4,1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EPOCH: 0, Train [Loss: 3.076, Accuracy: 0.037], Valid [Loss: 2.941, Accuracy: 0.052]\n",
      "EPOCH: 1, Train [Loss: 0.868, Accuracy: 0.755], Valid [Loss: 0.066, Accuracy: 1.000]\n",
      "EPOCH: 2, Train [Loss: 0.042, Accuracy: 1.000], Valid [Loss: 0.014, Accuracy: 1.000]\n",
      "EPOCH: 3, Train [Loss: 0.022, Accuracy: 1.000], Valid [Loss: 0.014, Accuracy: 1.000]\n",
      "EPOCH: 4, Train [Loss: 0.024, Accuracy: 1.000], Valid [Loss: 0.027, Accuracy: 1.000]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "\n",
    "    model.train()\n",
    "    n_train = 0\n",
    "    acc_train = 0\n",
    "    for x, t in dataloader_train:\n",
    "        n_train += t.size()[0]\n",
    "        model.zero_grad()\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        y = model(x)\n",
    "        loss = loss_function(y, t)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc_train += (torch.abs(y) < torch.tensor(0.05)).float().sum().item()\n",
    "        losses_train.append(loss.tolist())\n",
    "\n",
    "    model.eval()\n",
    "    n_val = 0\n",
    "    acc_val = 0\n",
    "    for x, t in dataloader_valid:\n",
    "        n_val += t.size()[0]\n",
    "        model.zero_grad()\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        y = model(x)\n",
    "        loss = loss_function(y, t)\n",
    "\n",
    "        acc_val += (torch.abs(y) < torch.tensor(0.05)).float().sum().item()\n",
    "        losses_valid.append(loss.tolist())\n",
    "\n",
    "    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n",
    "        epoch,\n",
    "        np.mean(losses_train),\n",
    "        acc_train/n_train,\n",
    "        np.mean(losses_valid),\n",
    "        acc_val/n_val\n",
    "    ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.2279152  0.33215547 0.        ]\n",
      "-0.001041979412548244\n",
      "[[ 0.6045858 ]\n",
      " [-0.7188493 ]\n",
      " [-0.34312043]]\n",
      "[0.29681978 0.23144877 0.06315789]\n",
      "-0.0007454908918589354\n",
      "[[nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "<ipython-input-4-9a735ee2f96b>:54: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return y.item(), vec_n/np.linalg.norm(vec_n)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    i += 500\n",
    "    print(x_train[i])\n",
    "    x = torch.tensor(x_train[i], dtype=torch.float, requires_grad=True)\n",
    "    y, n = model.sdf(x_train[i].reshape((3,1)))\n",
    "    print(y)\n",
    "    print(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_Lambert(I, x, l_point, n, k_d):\n",
    "    xl = l_point - x\n",
    "    r = np.linalg.norm(xl)\n",
    "    l = xl/r\n",
    "\n",
    "    # print(l)\n",
    "    # print(n)\n",
    "    return k_d*(I/r**2)*max(0, np.dot(l.T, n)[0][0])\n",
    "\n",
    "def rel_environment(I_a, k_a):\n",
    "    return k_a*I_a\n",
    "\n",
    "def raymarching(ray, forcus, sdf):\n",
    "    beta = 0.1\n",
    "    vec_ray = beta*(ray/np.linalg.norm(ray))\n",
    "    x = forcus + vec_ray\n",
    "    dist, vec_n= sdf(x)\n",
    "\n",
    "    flag = True\n",
    "    step = 0\n",
    "    while -1e-1 > dist or dist > 1e-1:\n",
    "        \n",
    "        pre_dist = dist\n",
    "        if dist > 0:\n",
    "            x = x + vec_ray\n",
    "            dist, vec_n = sdf(x)\n",
    "        else:\n",
    "            \n",
    "            x = x - 0.01*vec_ray\n",
    "            dist, vec_n = sdf(x)\n",
    "            flag = False\n",
    "\n",
    "\n",
    "        if flag and pre_dist < dist: #no material is same return\n",
    "            return forcus, np.zeros((3,1))\n",
    "\n",
    "        if step == 20:\n",
    "            return forcus, np.zeros((3,1))\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    return x, vec_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0.03697421 -0.00428233  0.09993895]\n[[ 0.2862191  -0.2738516   0.16842106]\n [-0.00353357 -0.19787987  0.2       ]\n [-0.03533569 -0.17667845  0.        ]\n ...\n [-0.29858658  0.04240283  0.11578947]\n [ 0.2720848   0.00353357  0.        ]\n [ 0.11307421  0.2508834   0.2       ]]\n"
     ]
    }
   ],
   "source": [
    "#camera\n",
    "camera = [0,0,3]\n",
    "camera = np.array(camera).reshape((3,1))\n",
    "#screen\n",
    "screen = np.zeros((500,500))\n",
    "#camera matrix\n",
    "K = np.eye(3)\n",
    "f_x = 20\n",
    "f_y = 20\n",
    "K[0,0] = f_x\n",
    "K[1,1] = f_y\n",
    "K[0,2] = 250\n",
    "K[1,2] = 250\n",
    "#parameter\n",
    "I = 5\n",
    "k_d = 10\n",
    "I_a = 1\n",
    "k_a = 1\n",
    "\n",
    "print(x_train.mean(axis=0))\n",
    "print(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  3%|▎         | 15/500 [00:08<04:24,  1.83it/s]<ipython-input-4-9a735ee2f96b>:54: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return y.item(), vec_n/np.linalg.norm(vec_n)\n",
      "100%|██████████| 500/500 [03:50<00:00,  2.17it/s]236095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "width = int(screen.shape[0]/2)\n",
    "hight = int(screen.shape[1]/2)\n",
    "n_find = 0\n",
    "for i in tqdm(range(-width, width)):\n",
    "    i = i/f_x\n",
    "    for j in range(-hight, hight):\n",
    "        j = j/f_y\n",
    "        forcus = [i, j, 1]\n",
    "        forcus = np.array(forcus).reshape((3,1))\n",
    "        ray = forcus - camera\n",
    "        x, vec_n = raymarching(ray, forcus, model.sdf)\n",
    "\n",
    "        if np.array_equal(forcus, x):\n",
    "            vec_sc = np.dot(K, forcus)\n",
    "            screen[int(vec_sc[0][0]), int(vec_sc[1][0])] = 0\n",
    "        else:\n",
    "            n_find += 1\n",
    "            vec_sc = np.dot(K, forcus)\n",
    "            screen[int(vec_sc[0][0]), int(vec_sc[1][0])] = rel_Lambert(I, x, camera, vec_n, k_d) + rel_environment(I_a,k_a)\n",
    "            #print(rel_Lambert(I, x, camera, vec_n, k_d))\n",
    "    \n",
    "print(n_find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"252.099904pt\" version=\"1.1\" viewBox=\"0 0 257.9275 252.099904\" width=\"257.9275pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-06-06T14:16:49.686666</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 252.099904 \nL 257.9275 252.099904 \nL 257.9275 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 228.221779 \nL 250.7275 228.221779 \nL 250.7275 10.781779 \nL 33.2875 10.781779 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p81d252af12)\">\n    <image height=\"218\" id=\"image4ac5c90a61\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"33.2875\" xlink:href=\"data:image/png;base64,\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\" y=\"-10.221779\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m0012b9ad19\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.50494\" xlink:href=\"#m0012b9ad19\" y=\"228.221779\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(30.32369 242.820216)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"76.99294\" xlink:href=\"#m0012b9ad19\" y=\"228.221779\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <g transform=\"translate(67.44919 242.820216)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"120.48094\" xlink:href=\"#m0012b9ad19\" y=\"228.221779\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 200 -->\n      <g transform=\"translate(110.93719 242.820216)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"163.96894\" xlink:href=\"#m0012b9ad19\" y=\"228.221779\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 300 -->\n      <g transform=\"translate(154.42519 242.820216)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"207.45694\" xlink:href=\"#m0012b9ad19\" y=\"228.221779\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 400 -->\n      <g transform=\"translate(197.91319 242.820216)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m1e916a0d9d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1e916a0d9d\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1e916a0d9d\" y=\"54.487219\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 58.286437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1e916a0d9d\" y=\"97.975219\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 101.774437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1e916a0d9d\" y=\"141.463219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 300 -->\n      <g transform=\"translate(7.2 145.262437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1e916a0d9d\" y=\"184.951219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 400 -->\n      <g transform=\"translate(7.2 188.750437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 228.221779 \nL 33.2875 10.781779 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 250.7275 228.221779 \nL 250.7275 10.781779 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 228.221779 \nL 250.7275 228.221779 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 10.781779 \nL 250.7275 10.781779 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p81d252af12\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"33.2875\" y=\"10.781779\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATIklEQVR4nO3dX2hc553G8e8zmj/6F1mSZTnCsjdOamiSkrTBeFO6DaV0SbYNdaAEvNDFF4HcZKFlF4qzhV16192L0qtcmLasod0GQ0vjhsJinJa9ydZJmnQ3TurakTeOaseKMamdyLI0nt9e6EiZyLL1b0ZzRu/zATFnXp2Z+Wl0zjPvec+ZcxQRmFm6Cq0uwMxayyFgljiHgFniHAJmiXMImCXOIWCWuKaFgKRHJJ2UdFrSgWa9jpmtjZpxnICkDuCPwF8D48BLwN9GxBsNfzEzW5Nm9QT2AKcjYiwipoFngb1Nei0zW4Nik553G/BO3f1x4C9vNrMkH7a4QsVikULBQzq2fNPT0xcjYsvC9maFgBZp+9iKLulJ4Mkmvf6GValUGBwcpFKpOARsRcbGxt5erL1ZITAObK+7Pwqcq58hIg4CB8E9geWqVCps3bqVYrFZ/zZLUbM+Sl4CdknaKakM7AOONOm1kuAAsGZpyhIVEVVJfw/8J9AB/CgiTjTjtVLgALBmatpSFRG/An7VrOdPhQPAms0jSznmALD14BDIKQeArRcvYTnU399PX1+fA8DWhZeynBkcHKSvr8/HANi68ZKWIw4AawUvbTnhALBW8RKXAw4AayUvdS3mALBW85LXQg4AywPvHWiBUqnE5s2b6ezsdABYyzkE1lmpVGLr1q2Uy+VWl2IGeHNgXTkALI8cAuvEAWB55RBYBw4AyzOHQJM5ACzvHAJN5ACwduC9A03S19fHpk2bKJVKrS7F7JYcAk3Q19fH4OCgjwGwtuCltMEcANZuvKQ2kAPA2pGX1gZxAFi78hLbAA4Aa2deatfIAWDtznsHVqmjo4OhoSG6urocANbWHAKr0NHRwfDwMF1dXa0uxWzN/BG2QnMBUKlUWl2KWUO4J7AC7gHYRuSewDI5AGyjcggsgzcBbCPz5sASyuUymzdvplKpeC+AbUgOgVvo6elhy5YtXvltQ/PSfRMOAEuFl/BFOAAsJV7KF3AAWGq8pNdxAFiKllzaJf1I0oSk1+vaBiUdlXQqux2o+93Tkk5LOinp4WYV3kiS6O3tdQBYkpazxP878MiCtgPAsYjYBRzL7iPpHmAfcG/2mGckdTSs2gaTRE9PDyMjIwwNDTkALElLLvUR8V/ApQXNe4FD2fQh4LG69mcj4lpEnAFOA3saU2pjlctlhoaG2LJli68JaElb7XECWyPiPEBEnJc0nLVvA/67br7xrO0Gkp4Enlzl669aoVCYPxNwR0duOylm66bRBwtpkbZYbMaIOAgcBJC06DyN1tvbO38acH/ym81abQhckDSS9QJGgImsfRzYXjffKHBuLQU2QqVSYdOmTXR3d3vlN1tgtWvEEWB/Nr0feK6ufZ+kiqSdwC7g+NpKXL2Ojg42bdrE7bffTm9vrwPAbBFL9gQk/RT4AjAkaRz4F+C7wGFJTwBngccBIuKEpMPAG0AVeCoirjep9lvq6upiaGiIjo4Or/xmt6CIddkcv3URDRwT6OzspL+/3yP+ZguMjY29EhG7F7ZvmG8RFotFbrvtNjZt2uSV32wF2j4E5g74mTvttwPAbGXaOgQ6OzsZHBykXC575TdbpbYMgVKpRF9fH729vT7gx2yN2ioECoUC3d3d9Pf3Uy6XW12O2YbQNiHQ09NDf3+/j/Yza7Dch0C5XGbTpk309PR45TdrgtyGQKFQoLe3l4GBAW/3mzVRLkOgs7OToaEhisWiP/3NmixXIVAsFtm8ebOv9Gu2jnITAv39/fT19VEs5qYksyTkYo0rlUr09/f709+sBXKx1klyAJi1iNc8s8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBLnEDBLnEPALHEOAbPEOQTMEucQMEucQ8AscQ4Bs8Q5BMwS5xAwS5xDwCxxDgGzxDkEzBLnEDBLnEPALHEOAbPELRkCkrZL+rWkNyWdkPSNrH1Q0lFJp7LbgbrHPC3ptKSTkh5u5h9gZmuznJ5AFfjHiLgbeBB4StI9wAHgWETsAo5l98l+tw+4F3gEeEaSLyZollNLhkBEnI+I32XTV4A3gW3AXuBQNtsh4LFsei/wbERci4gzwGlgT4PrNrMGWdGYgKQ7gM8AvwW2RsR5mA0KYDibbRvwTt3DxrM2M8uhZYeApF7gZ8A3I+LyrWZdpC0Web4nJb0s6eVarbbcMsyswZYVApJKzAbATyLi51nzBUkj2e9HgImsfRzYXvfwUeDcwueMiIMRsTsidvsSZGats5y9AwJ+CLwZEd+r+9URYH82vR94rq59n6SKpJ3ALuB440o2s0ZazlWJPwf8HfC/kl7L2v4J+C5wWNITwFngcYCIOCHpMPAGs3sWnoqI640u3MwaQxE3bK6vu0qlEqOjo60uw2xDGxsbeyUidi9s98a4WeIcAmaJcwiYJc4hYJY4h4BZ4hwCZolzCJglziFgljiHgFniHALWELNfMbF25BCwNSuVSg6BNuYQsBWr/+p3V1cXAwMD5OE7KLY6DgFbtXK5zJ133glApVLB54VoT/6v2YrNnQlq8+bNVCoVBgYGGB4eprOzc36ewcHBVpVnK7Sc8wmY3aBYLHL33Xfz4Ycfcu7cOa5cuXLD73fs2MH7778PwJUrV7zJkFPuCdiKFQoFRkZG+NrXvsa77757QwAATExMcPbsWSYnJ5mZmWH79u0MDQ1RLpdbULHdinsCtiKFQoFyuczOnTu5cOEC77zzzi3nr1arVKtVzp49S7FYZHBwkKmpKWZmZrh+/TrT09PrVLndjHsCtmyS6OnpYXp6mt7eXq5du8b27duXfmCmWq0yMTHB5cuXuXbt2nwolMtlDyq2kN95W5ZCoUBXVxdTU1PUajWOHz/Ou+++y6OPPsr9999PsbiyTmWtVmNycpJLly4RERSLRbq7u+nu7vYxB+vMIWBLkkSxWJzvxgNcvHiRX/7yl0xMTPDQQw/x+c9/ftWf5jMzM0xPTzM5OcnU1BSdnZ2USiX3ENaJxwRsSZKoVqssvEjMpUuX+MUvfsEDDzzAfffdx8zMDK+99hoffPDBql+rVqtx9erV+ftzQTA3tmCN5xCwWyoUCvMr4WJmZmZ46aWXqFarfPKTn2R4eJgXXnhhftfgWs0NHBaLRUqlEtevz5693letahz3teymJN0yAObUajVeffVVjh49yrVr1/jsZz/LwMBAQ7ftq9UqMzMz1Go1IoJSqUSxWPT4QQM4BGxRkuY3A5ajVqsxMTHBiy++yPT0NA8++CB33XVXU1bSiGBmZma+tkKh4EBYA4eALUrSqrrcly5d4sUXX2R8fJwdO3awY8eOpq6cEUGtVqNarc4PYDoMVsYhYDcoFAprOsR3cnKSEydO8Kc//Ylt27Zx7733rsuRgnNhAB9tynjvwtL8DtnHFAqF+e3utajVapw6dYozZ85QKpW46667PvYFo2aKiPkeQq1Wo1AozIeC3cjvis1b7SbAzdRqNc6fP89bb71FoVDgE5/4BAMDAw17/pXUMRcMc2HgTYaPOAQM+GggsBkuX77M22+/zZUrVxgeHqavr68pr7OU+h4CfPQ3px4IPk7A5jVz3/sHH3zA5OQkt99+O0NDQ3R3dzMxMdGy/f0LN3fmgiDFrzu7J2BIWpeFv1arzX/1uFwuMzQ0lJvt9PrNhdTk4z9gLbNeATCnVqvx3nvvcfHiRYrFYu7OMXCzHsJG5hBI2HoHQL3Jycn5Q4v7+/tzFQT1Utg8cAgkqpUBMGdycpKLFy8yMzNDX18f3d3dLa0nVQ6BRLU6AObUajX+/Oc/Mz09TWdnp4OgBZYMAUmdko5L+r2kE5K+k7UPSjoq6VR2O1D3mKclnZZ0UtLDzfwDrP3VajWuXLnC1atXKZfLdHd352bAMAXLeaevAV+MiPuBTwOPSHoQOAAci4hdwLHsPpLuAfYB9wKPAM9I6mhC7baBRARXr15lamqKYrFIT0+Pg2CdLPkux6y5s0SUsp8A9gKHsvZDwGPZ9F7g2Yi4FhFngNPAnkYWbavTDiPdU1NTTE5OEhHuEayTZb3DkjokvQZMAEcj4rfA1og4D5DdDmezbwPqT0E7nrUtfM4nJb0s6WWfIGJ95GUcYCnVapXJyUlqtRrd3d253XOwUSwrBCLiekR8GhgF9kj61C1mX+zj5oalLyIORsTuiNjttLeFarUaU1NTXL9+ff6sQtYcK1r7IuJ94DfMbutfkDQCkN1OZLONA/XnoR4Fzq21UEvP3PkGq9UqxWKRzs7OttikaTfL2TuwRVJ/Nt0FfAn4A3AE2J/Nth94Lps+AuyTVJG0E9gFHG9w3ZaQ6enp+fME+DLojbecLxCNAIeyEf4CcDginpf0InBY0hPAWeBxgIg4Iekw8AZQBZ6KiOvNKd9SMXfForlNg8XOfmyrozwMFlUqlRgdHW11GdYG5s4nCDgIVmhsbOyViNi9sN0jctZWarXa/FmHi8WidyE2gN9BazsRMd8LKBaLK74Emn2cQ8Da1txViebOMmyr4xCwtlar1eavSuTTja+OQ8DaXn0QdHR0OAhWyCFgG0L9OEFHR4cHDFfAG1K2ocztMpwLAe9CXJrj0jac+s0D9wiW5nfINqS5sweDg2Apfndsw1oYBB4wXJxDwDa0xa44ZB/nELAkOAhuziFgyZi7MKmvUPxxficsKR4wvJHfBUtO/TiBBwwdApaw+s2DlIPARwxa0uY2DXxpcrOE1Y8TpNgjcAiYkXYQOATM6qQYBA4BswVSCwKHgNki6oNgo4eBQ8DsJur3FGzkIHAImN1CCgOGDgGzZdjIQeAQMFumjRoEDgGzFZjbPNhIQeAQMFuFjRQEDgGzVdooQeAQMFuDjfCFI4eAWeIcAmaJcwiYJc4hYJa4ZYeApA5Jr0p6Prs/KOmopFPZ7UDdvE9LOi3ppKSHm1G4mTXGSnoC3wDerLt/ADgWEbuAY9l9JN0D7APuBR4BnpHU0ZhyzazRlhUCkkaBrwA/qGveCxzKpg8Bj9W1PxsR1yLiDHAa2NOQas2s4ZbbE/g+8C2g/jrPWyPiPEB2O5y1bwPeqZtvPGszsxxaMgQkPQpMRMQry3zOxQ6huuGICklPSnpZ0su+hrxZ6yznlOOfA74q6ctAJ9An6cfABUkjEXFe0ggwkc0/Dmyve/wocG7hk0bEQeAgQKVSaf/Drsza1JI9gYh4OiJGI+IOZgf8XoiIrwNHgP3ZbPuB57LpI8A+SRVJO4FdwPGGV25mDbGWi498Fzgs6QngLPA4QESckHQYeAOoAk9FxPU1V2pmTaE8fAGiUqnE6Ohoq8sw29DGxsZeiYjdC9t9xKBZ4hwCZolzCJglziFgljiHgFniHAJmiXMImCXOIWCWOIeAWeIcAmaJcwiYJc4hYJY4h4BZ4hwCZolzCJglziFgljiHgFniHAJmiXMImCXOIWCWOIeAWeIcAmaJcwiYJc4hYJY4h4BZ4hwCZolzCJglziFgljiHgFniHAJmiXMImCXOIWCWOIeAWeIcAmaJcwiYJc4hYJY4h4BZ4hwCZolTRLS6BiS9B3wIXGx1Lcs0RPvUCu1Vr2ttnr+IiC0LG3MRAgCSXo6I3a2uYznaqVZor3pd6/rz5oBZ4hwCZonLUwgcbHUBK9BOtUJ71eta11luxgTMrDXy1BMwsxZoeQhIekTSSUmnJR1odT0Akn4kaULS63Vtg5KOSjqV3Q7U/e7prP6Tkh5e51q3S/q1pDclnZD0jbzWK6lT0nFJv89q/U5ea617/Q5Jr0p6Pu+1rlpEtOwH6ADeAu4EysDvgXtaWVNW10PAA8DrdW3/BhzIpg8A/5pN35PVXQF2Zn9PxzrWOgI8kE3fBvwxqyl39QICerPpEvBb4ME81lpX8z8A/wE8n+flYC0/re4J7AFOR8RYREwDzwJ7W1wTEfFfwKUFzXuBQ9n0IeCxuvZnI+JaRJwBTjP7d62LiDgfEb/Lpq8AbwLb8lhvzPogu1vKfiKPtQJIGgW+AvygrjmXta5Fq0NgG/BO3f3xrC2PtkbEeZhd8YDhrD03f4OkO4DPMPsJm8t6s+71a8AEcDQiclsr8H3gW0Ctri2vta5aq0NAi7S12+6KXPwNknqBnwHfjIjLt5p1kbZ1qzcirkfEp4FRYI+kT91i9pbVKulRYCIiXlnuQxZpa4tludUhMA5sr7s/CpxrUS1LuSBpBCC7ncjaW/43SCoxGwA/iYifZ825rRcgIt4HfgM8Qj5r/RzwVUn/x+xm6hcl/Tinta5Jq0PgJWCXpJ2SysA+4EiLa7qZI8D+bHo/8Fxd+z5JFUk7gV3A8fUqSpKAHwJvRsT38lyvpC2S+rPpLuBLwB/yWGtEPB0RoxFxB7PL5QsR8fU81rpmrR6ZBL7M7Ij2W8C3W11PVtNPgfPADLMJ/wSwGTgGnMpuB+vm/3ZW/0ngb9a51r9ittv5P8Br2c+X81gvcB/walbr68A/Z+25q3VB3V/go70Dua51NT8+YtAsca3eHDCzFnMImCXOIWCWOIeAWeIcAmaJcwiYJc4hYJY4h4BZ4v4f1nnHMrt0kg4AAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(screen.T, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}